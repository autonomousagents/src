\relax 
\@writefile{toc}{\contentsline {section}{\numberline {1}Assignment 1: Single Agent Planning}{1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}(M) Simulating the Environment}{1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}(SC) Iterative Policy Evaluation}{1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}(SC) State space reduction}{1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4}(M) Value Iteration}{1}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces  Colormap of the $V$-values resulting from value iteration for $\theta =0$ and $\gamma = 0.9$. The brighter the color the higher the corresponding $V$-value.}}{2}}
\newlabel{colormapValueIteration}{{1}{2}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces The $V$-values for Value Iteration, with $\gamma $ = 0.1 and the prey at position (5,5). The convergence speed is 20 iterations.}}{3}}
\newlabel{valueiterationone}{{1}{3}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces The $V$-values for Value Iteration, with $\gamma $ = 0.5 and the prey at position (5,5). The convergence speed is 28 iterations.}}{3}}
\newlabel{valueiteration2}{{2}{3}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces The $V$-values for Value Iteration, with $\gamma $ = 0.7 and the prey at position (5,5). The convergence speed is 31 iterations.}}{4}}
\newlabel{valueiteration3}{{3}{4}}
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces The $V$-values for Value Iteration, with $\gamma $ = 0.9 and the prey at position (5,5). The convergence speed is 34 iterations.}}{4}}
\newlabel{valueiteration4}{{4}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.5}(SC) Policy Iteration}{5}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Appendix}{6}}
