\relax 
\@writefile{toc}{\contentsline {section}{\numberline {1}Assignment 1: Single Agent Planning}{1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}(M) Simulating the Environment}{1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}(SC) Iterative Policy Evaluation}{1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}(SC) State space reduction}{1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4}(M) Value Iteration}{1}}
\newlabel{tab:valueiterationone}{{1.4}{2}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces The V-values for value iteration, with $\gamma $ = 0.1 and the prey at position (5,5). The convergence speed is 20 iterations.}}{2}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces The V-values for value iteration, with $\gamma $ = 0.5 and the prey at position (5,5). The convergence speed is 28 iterations.}}{2}}
\newlabel{valueiteration2}{{2}{2}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces The V-values for value iteration, with $\gamma $ = 0.7 and the prey at position (5,5). The convergence speed is 31 iterations.}}{3}}
\newlabel{valueiteration3}{{3}{3}}
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces The V-values for value iteration, with $\gamma $ = 0.9 and the prey at position (5,5). The convergence speed is 34 iterations.}}{3}}
\newlabel{valueiteration4}{{4}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.5}(SC) Policy Iteration}{4}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Appendix}{5}}
